<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Kernel Density Estimation · ScenTrees.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="ScenTrees.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">ScenTrees.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorial1/">Introduction</a></li><li><a class="tocitem" href="../tutorial2/">Scenario Trees</a></li><li><a class="tocitem" href="../tutorial3/">Scenario Lattices</a></li><li><a class="tocitem" href="../tutorial31/">Stochastic processes</a></li><li><a class="tocitem" href="../tutorial4/">Stochastic approximation process</a></li><li class="is-active"><a class="tocitem" href>Kernel Density Estimation</a><ul class="internal"><li><a class="tocitem" href="#Implementation-of-the-above-process-1"><span>Implementation of the above process</span></a></li></ul></li><li><a class="tocitem" href="../tutorial5/">Performance of <code>ScenTrees.jl</code></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Kernel Density Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Kernel Density Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/kirui93/ScenTrees.jl/blob/master/docs/src/tutorial/tutorial41.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Kernel-Density-Estimation-1"><a class="docs-heading-anchor" href="#Kernel-Density-Estimation-1">Kernel Density Estimation</a><a class="docs-heading-anchor-permalink" href="#Kernel-Density-Estimation-1" title="Permalink"></a></h1><p>This is a non-parametric technique for generating trajectories used to generate and improve scenario trees and scenario lattices in the stochastic approximation algorithm. This is a case where the distributions are not available explicitly and so the samples can be drawn from a data by proper approximations. It involves two steps:</p><pre><code class="language-none">1. Density estimation and,
2. Stochastic approximation process.</code></pre><p>The stochastic approximation process has already been described above so we will concentrate on the density estimation step. The density estimation step involves two steps:</p><pre><code class="language-none">(a) Estimation of the distribution of conditional densities and,
(b) Composition method</code></pre><p>We estimate the distribution of transition densities given the history of the process. This distribution is estimated by the non-parametric kernel density estimation. The density at stage <span>$t+1$</span> conditional on the history <span>$\mathbf{x_{t}} = (x_0,x_{i_{1}},x_{i_{2}},\ldots,x_{i_{t}})$</span> is estimated by</p><div>\[\hat{f}_{t+1}(x_{t+1}|\mathbf{x_{t}}) = \sum_{j=1}^{N} w_j(\mathbf{x_{t}}) \cdot k_{h_N}(x_{t+1} - \xi_{j,t+1})\]</div><p>where <span>$k(.)$</span> is a kernel function, <span>$h_N$</span> is the bandwidth and <span>$k_{h_N}$</span> is the weighted kernel function.</p><p>The weights are given by</p><div>\[w_j(\mathbf{x_{t}}) = \frac{k\big(\frac{x_{i_1} - \xi_{j,1}}{h_N}\big)\cdot \ldots \cdot k\big(\frac{x_{i_t} - \xi_{j,t}}{h_N}\big)}{\sum_{\ell=1}^{N}k\big(\frac{x_{i_1} - \xi_{l,1}}{h_N}\big)\cdot \ldots \cdot k\big(\frac{x_{i_t} - \xi_{l,t}}{h_N}\big)}.\]</div><p>Notice from above that the weights depend on the history <span>$\mathbf{x_{t}}$</span> up to stage <span>$t$</span> only. Also, the weights sum up to 1 for every <span>$\mathbf{x_{t}}$, i.e., $\sum_{j=1}^{N} w_j(\mathbf{x_{t}}) = 1$</span>.</p><p>We use the composition method to find the samples from the conditional distribution <span>$\hat{f}_{t+1}(.|\mathbf{x_{t}})$</span> as follows. Pick a random number <span>$U \in (0,1)$</span> where <span>$U$</span> is uniformly distributed then find a summation index <span>$j^{\star} \in {1,2,\ldots,N}$</span> such that <span>$\sum_{j=1}^{j^{\star}-1} w_j(\mathbf{x_{t}}) &lt; U \leq \sum_{j=1}^{j^{\star}} w_j(\mathbf{x_{t}}).$</span></p><p>The cumulative sum of weights leads to a high probability of picking a data path near the observation.</p><p>The value of the data <span>$\xi_t$</span> is obtained by setting the value at stage <span>$t$</span> to</p><div>\[\xi_t = X_{j^{\star,t}} + \text{rand}_{k_{h_N}}\]</div><p>where <span>$\text{rand}_{k_{h_N}}$</span> is a random value sampled from the kernel estimator using the composition method.</p><p>The generated data point is according to the distribution of the density at the current stage and dependent on the history of all the data points. It has been shown that the choice of the kernel does not have an important effect on density estimation. Hence, we employ the following logistic kernel as default: <span>$k(x) = \frac{1}{(e^x + e^{-x})^2}.$</span></p><p>One of the most important factor to consider in density estimation is the bandwidth. We use the Silverman&#39;s rule of thumb to obtain the bandwidths for each of the data columns as follows <span>$h_N = \sigma(X_t)\cdot N^{\frac{-1}{N+4}}$</span> where <span>$N$</span> is the number of available trajectories and <span>$\sigma(X_t)$</span> is the standard deviation of data in stage <span>$t$</span>.</p><p>Using the above procedure, every new sample path starts with <span>$\mathbf{\tilde{\xi_1}} := (x_1)$</span>. Using the composition method, we find a new sample <span>$\tilde{\xi_2}$</span> from <span>$\hat{f}_1(.|\mathbf{\tilde{\xi_1}})$</span> at the first stage. Next, we set <span>$\mathbf{\tilde{\xi_2}} = (\tilde{\xi_1},\tilde{\xi_2})$</span> and generate a new data point <span>$\tilde{\xi_2}$</span> from <span>$\hat{f}_2(.|\mathbf{\tilde{\xi_1}})$</span>  at the second stage. The process continues in that manner until the final stage <span>$T$</span> where we get the final new sample path <span>$\mathbf{\tilde{\xi_T}} = (\tilde{\xi_0},\tilde{\xi_1},\ldots,\tilde{\xi_T})$</span> which is generated form the initial data <span>$\mathbf{x_{t}}$</span>.</p><p>The new sample path <span>$\mathbf{\tilde{\xi_T}}$</span> is what we will feed in the stochastic approximation algorithm to generate either a scenario tree or a scenario lattice.</p><h2 id="Implementation-of-the-above-process-1"><a class="docs-heading-anchor" href="#Implementation-of-the-above-process-1">Implementation of the above process</a><a class="docs-heading-anchor-permalink" href="#Implementation-of-the-above-process-1" title="Permalink"></a></h2><p>The above process is implemented in our library in <code>KernelDensityEstimation.jl</code>.In this script, we use the concept of function closures which we assume that the user of this library is aware of. The user is required to provide a data in 2 dimension, i.e., a matrix of Float64 or Int64, to this function and also the distribution of the kernel that he/she wants to use. The default kernel distribution is the Logistic kernel. The kernel distribution should conform to the distributions stated in <a href="https://github.com/JuliaStats/Distributions.jl">Distributions.jl</a> library.</p><p>Most of the times when you load the data into Julia, it recognizes it as a <code>DataFrame</code> type. But we have wrote the function in a manner that the user should provide a Matrix of either floats or integers. In the following procedure, we use the function <code>Matrix</code> to convert the loaded dataframe into a matrix which is the right type of input into the function.</p><p>The function <code>KernelScenarios(data::Union{Array{Int64,2},Array{Float64,2}}, kernelDistribution = Logistic; Markovian = true)</code> takes a <span>$(N \times T)$</span> dimensional data and the distribution of the kernel you want to employ. The <span>$N$</span> rows of the data are the number of trajectories in the initial data and the <span>$T$</span> columns is the number of stages in in each trajectory of the data. We also let the user to specify whether the process he/she is creating is a Markovian process or not. We are aware that scenario lattices are natural discretization of Markovian process. Hence the user should create samples for a scenario tree for the condition <code>Markovian=false</code> and scenario lattices for the condition <code>Markovian = true</code>.</p><p>Since <code>TreeApproximation!</code> and <code>LatticeApproximation</code> function needs a process function for generating samples that doesn&#39;t take any inputs, we employ the concept of function closures inside the above function. The function <code>KernelScenarios(data,kernelDistribution;Markovian=true)</code> is a getfield type of a function closure and so is sufficient to be a function required for stochastic approximation process.</p><p>To confirm the above statement, consider a <span>$1000x5$</span> dimsneional data from random walk. What is important to be said is that we use the package <a href="https://github.com/JuliaData/CSV.jl"><code>CSV</code>.jl</a> to read the data into Julia and since we need the data in matrix form, we use the function <code>Matrix</code> from the package <a href="https://github.com/JuliaData/DataFrames.jl"><code>DataFrames.jl</code></a> to convert the dataframe into an array in two dimension which is then the input of our function.</p><pre><code class="language-julia">julia&gt; using ScenTrees, CSV
julia&gt; data = CSV.read(&quot;.../RandomDataWalk.csv&quot;)
julia&gt; Rdw = Matrix(data)
julia&gt; Kdt = KernelScenarios(Rwd,Logistic;Markovian=true)
(::getfield(ScenTrees, Symbol(&quot;#closure#52&quot;)){Array{Float64,2},Int64,Int64,Array{Float64,1},Array{Float64,1},Array{Float64,1}}) (generic function with 1 method)
julia&gt; ExampleTraj = KernelScenarios(Rwd,Logistic;Markovian = true)()
5-element Array{Float64,1}:
  2.9313
 -2.0964
  3.7671
  2.1476
  0.9424</code></pre><p>As in <code>ExampleTraj</code> above, this function returns is a new sample according to the distribution of the density at the current stage and dependent on the history of all the data points.</p><p>We use the above data to approximate a scenario lattice in <code>5</code> stages with a branching structure of <span>$(1\times 3\times 4\times 5\times6)$</span>  and <span>$100,000$</span> number of iterations as follows:</p><pre><code class="language-julia">julia&gt; KernExample = LatticeApproximation([1,3,4,5,6],KernelScenarios(Rwd,Logistic;Markovian=true),100000);
julia&gt; PlotLattice(KernExample)</code></pre><p>The above plot function gives the following plot result:</p><p><img src="../../assets/KernLattice.png" alt="Scenario Lattice From Kernel Trajectories"/></p><p>To generate a scenario tree using the same process, we use the following procedure:</p><pre><code class="language-julia">julia&gt; KernTree = TreeApproximation!(Tree([1,2,2,2],1),KernelScenarios(gsdata,Logistic;Markovian=false),100000,2,2);
julia&gt; treeplot(KernTree)</code></pre><p><img src="../../assets/kerneltree.png" alt="Scenario Tree From Kernel Trajectories"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tutorial4/">« Stochastic approximation process</a><a class="docs-footer-nextpage" href="../tutorial5/">Performance of <code>ScenTrees.jl</code> »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Friday 22 November 2019 15:41">Friday 22 November 2019</span>. Using Julia version 1.1.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
